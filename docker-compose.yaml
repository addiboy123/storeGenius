version: '3.8'

services:
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
      - ./Modelfile:/Modelfile  # Mount Modelfile into container
    entrypoint: >
      sh -c "ollama create storeGeniusLLM -f /Modelfile && ollama serve"
    restart: unless-stopped

  storegenius-api:
    build:
      context: ./ML
    ports:
      - "5050:5050"
    depends_on:
      - ollama
      - backend
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - BACKEND_URL=http://backend:7000
    restart: unless-stopped

  frontend:
    build:
      context: ./projectAPI_URL
    ports:
      - "5173:5173"
    depends_on:
      - backend
      - storegenius-api
    environment:
      - VITE_BACKEND_URL=http://backend:7000
      - VITE_API_URL=http://storegenius-api:5050
    restart: unless-stopped

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "7000:7000"
    depends_on:
      - storegenius-api
    environment:
      - SECRET_KEY=${SECRET_KEY}
      - PORT=${PORT}
      - MONGO_URI=${MONGO_URI}
      - API_URL=http://storegenius-api:5050
    restart: unless-stopped

volumes:
  ollama-data:
